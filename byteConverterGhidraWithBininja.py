import os
import re
import sys
from pathlib import Path
from binaryninja import *
from binaryninja import lineardisassembly
from binaryninja.function import DisassemblySettings
from binaryninja.enums import DisassemblyOption, LinearDisassemblyLineType, InstructionTextTokenType

import multiprocessing
from multiprocessing import Pool, Value, Lock
import tempfile
from functools import partial

import time
from datetime import datetime

import pyhidra
pyhidra.start()

import ghidra
from ghidra.app.util.headless import HeadlessAnalyzer
from ghidra.program.flatapi import FlatProgramAPI
from ghidra.base.project import GhidraProject
from java.lang import String as jstr
from ghidra.app.decompiler.flatapi import FlatDecompilerAPI


from ghidra.program.model.listing import CodeUnit
from ghidra.program.model.pcode import PcodeOp
from ghidra.app.decompiler import DecompInterface
from ghidra.util.task import ConsoleTaskMonitor
from ghidra.program.model.listing import Function, FunctionManager
# Import Ghidra scripting API
from ghidra.program.model.symbol import SourceType
from ghidra.program.model.address import Address, AddressSet
from ghidra.program.model.address import AddressFactory
from ghidra.app.decompiler import DecompileOptions
from ghidra.app.decompiler import DecompileResults
#from ghidra.framework.plugintool.util import DecompilerCallbackHandler

# import resource
# import signal

# class MemoryLimitException(Exception):
#     """
#     Custom exception indicating memory limitation has been reached.
#     """
#     pass

# def handle_memory_limit(signum, frame):
#     raise MemoryLimitException("Memory limit reached during analysis")

# memory_limit_gb = 48
# memory_limit_bytes = memory_limit_gb * 1024 * 1024 * 1024

# # Set soft memory limit (adjust based on your system)
# resource.setrlimit(resource.RLIMIT_AS, (memory_limit_bytes, resource.RLIM_INFINITY))  #48GB soft limit

# signal.signal(signal.SIGSEGV, handle_memory_limit)





def process_file(smp_dir, id):
    global counter
    global errorCounter
    global errorIDs
    global lock
    global binLock

    #print("Processing file: " + id)
# Read the .bytes file and convert it to a byte string
    with smp_dir.joinpath(id + ".bytes").open() as file:
        data = file.read()
        items = data.split()
        byte_list = [bytes.fromhex(item) for item in items if len(item) == 2 and item != "??"]
        byte_string = b"".join(byte_list)

    #print("File convert write: " + id)
    with tempfile.NamedTemporaryFile(delete=False) as temp:
    # Write the byte string to a file
        temp.write(byte_string)
        

    print(temp.name)



    bininjaBaseAddress = 0
    bininjaFunctions = []
    bininjaArchDetected = ""

    with binLock:
        print("File with active lock: " + id)
        #binaryninja.set_worker_thread_count(os.cpu_count()-6)
        # Set log level to 'error' to mute warnings
        #binaryninja.disable_default_log()


        # sometimes need to reduce the number of threads if the binary is causing a segmentation fault in binary ninja
        binaryninja.set_worker_thread_count(1)


        #print(binaryninja.Settings().keys())
        #print(f"Memory limit set to: {binaryninja.Settings().get_integer('analysis.limits.cacheSize')} bytes")

        #sometimes need to reduce the max size of a function if the binary is causing a oom killed from os
        binaryninja.Settings().set_integer("analysis.limits.maxFunctionSize", 2048) #half limit
        #binaryninja.Settings().set_integer("analysis.limits.maxFunctionSize", 8192) #double limit
        #print(f"Memory limit set to: {binaryninja.Settings().get_integer('analysis.limits.maxFunctionSize')} bytes")

        #sometimes play with number of functions update to allow weird binaries to be analyzed
        binaryninja.Settings().set_integer("analysis.limits.maxFunctionUpdateCount", 1) #triple limit
        #print(f"Memory limit set to: {binaryninja.Settings().get_integer('analysis.limits.maxFunctionUpdateCount')} bytes")

        #try a empty
        binaryninja.Settings().set_bool('analysis.linearSweep.permissive', True)
        #binaryninja.log.set_log_level(binaryninja.log.LogLevel.DebugLog)
        # Open the file with the appropriate BinaryViewType
        try:
            bv = binaryninja.load(temp.name)
            
            if bv.arch is None:
                print("Raw")
                bv = binaryninja.load(temp.name, options={'loader.architecture': 'x86_64'})    
            print("Binary View load: " + id)
            # # Perform analysis on the binary view
            bv.update_analysis_and_wait()
            #print("number of functions: " + str(len(bv.functions)))

        
            if len(bv.functions) == 0:
                print("no functions")
                bv = binaryninja.load(temp.name, options={'loader.architecture': 'x86'})

            bv.update_analysis_and_wait()
            #print("number of functions: " + str(len(bv.functions)))
            if len(bv.functions) == 0:
                print("no functions")
                bv = binaryninja.load(temp.name, options={'loader.architecture': 'x86_16'})


            bininjaArchDetected = bv.arch.name
            print(bininjaArchDetected)
            bv.update_analysis_and_wait()

        except:
            print("Error loading binary view")
            with lock:
                errorCounter.value += 1
                errorIDs.append(id)
                print(errorCounter.value)
            return

        print("Binary View analysis: " + id)

        #bv.update_analysis_and_wait()
        try:
            settings = DisassemblySettings()
            settings.set_option(DisassemblyOption.ShowVariableTypesWhenAssigned)
            settings.set_option(DisassemblyOption.GroupLinearDisassemblyFunctions)
            settings.set_option(DisassemblyOption.WaitForIL)

            bininjaBaseAddress = bv.start
            
            for func in bv.functions:
                bininjaFunctions.append((func.start, func.highest_address))


        except:
            print("Error loading binary view")
            with lock:
                errorCounter.value += 1
                errorIDs.append(id)
                print(errorCounter.value)
            return

        #binaryninja.shutdown()

        ############################################################################################################################
        ############################################################################################################################
        ############################################################################################################################
        #Marks beginning of Ghidra code after finding function ranges in binary ninja
        ############################################################################################################################
        ############################################################################################################################
        ############################################################################################################################
        binary_ninja_to_ghidra_x86 = {
            "x86": "x86:LE:32:default",
            "x86_64": "x86:LE:64:default",
            "x86_16": "x86:LE:16:Real Mode",
            "x86_32": "x86:LE:32:default",
            "x86_64": "x86:LE:64:default",
            "x86_16m": "x86:LE:16:Real Mode",
            "x86_32s": "x86:LE:32:Protected Mode",
            "x86_64s": "x86:LE:64:Long Mode",
            "x86_real": "x86:LE:16:Real Mode",
            "x86_protected": "x86:LE:32:Protected Mode",
            "x86_long": "x86:LE:64:Long Mode",
            "metapc": "x86:LE:32:default",
            "metapc_16": "x86:16",
            "armv7": "ARM:LE:32:v7",
            "aarch64": "AARCH64:LE:64:v8A",
            "thumb2": "ARM:LE:32:v7T",  # Assuming thumb2 is under ARMv7 in Ghidra
            "mips32": "MIPS:BE:32:default",
            "mips64": "MIPS:BE:64:64-32addr",
            "ppc32": "PowerPC:BE:32:default",
            "ppc64": "PowerPC:BE:64:default"
        }
        if bininjaArchDetected in binary_ninja_to_ghidra_x86:
            ghidraArch = binary_ninja_to_ghidra_x86[bininjaArchDetected]       
            print(ghidraArch)



        # Open the file in ghidra

        with pyhidra.open_program(temp.name, language= ghidraArch, compiler = 'gcc' ) as flat_api:
            print("File with active lock: " + id)
            currentProgram = flat_api.getCurrentProgram()
            decompInterface = FlatDecompilerAPI(flat_api)


            ghidra_base_address = currentProgram.getImageBase().getOffset()

            options = DecompileOptions()
            options.grabFromProgram(currentProgram)
            #callbackHandler = DecompilerCallbackHandler(currentProgram)

            ghidra_normalized_function_tuples = [
            (start - bininjaBaseAddress + ghidra_base_address, end - bininjaBaseAddress + ghidra_base_address)
            for start, end in bininjaFunctions
            ]


            # Get the function manager and address factory
            function_manager = currentProgram.getFunctionManager()
            address_factory = currentProgram.getAddressFactory()
            address_space = address_factory.getDefaultAddressSpace()


            # Define functions in Ghidra
            for start, end in ghidra_normalized_function_tuples:
                start_address = currentProgram.getImageBase().add(start)
                end_address = currentProgram.getImageBase().add(end-1)
                
                # Get any existing functions that overlap with the new function range
                overlapping_functions = function_manager.getFunctions(start_address, True)
                for func in overlapping_functions:
                    if func.getBody().intersects(AddressSet(start_address, end_address)):
                        function_manager.removeFunction(func.getEntryPoint())
                        print(f"Removed existing function at {func.getEntryPoint()} overlapping with range {start_address} - {end_address}")

                # Create the new function
                try:
                    function = function_manager.createFunction(None, start_address, AddressSet(start_address, end_address), SourceType.USER_DEFINED)
                    print(f"Created function from {start_address} to {end_address}")
                except Exception as e:
                    print(f"Error creating function from {start_address} to {end_address}: {e}")

            listing = currentProgram.getListing()
            

            # for codeUnit in listing.getCodeUnits(True):
            #     print(codeUnit)


            #outputPath = smp_dir.joinpath(id + ".pcode")
            try:
                #with print("test") as f:
                with open("garbade.txt", 'w') as f:
                
                # Get all functions and instructions in the program
                    functions = list(currentProgram.getFunctionManager().getFunctions(True))
                    instructions = list(currentProgram.getListing().getInstructions(True))
                    print(functions)

                    # Combine and sort the functions and instructions by their address
                    funcs_and_instrs = sorted(functions + instructions, key=lambda x: x.getEntryPoint() if isinstance(x, Function) else x.getAddress())

                    # Keep track of the functions that have been processed
                    processed_functions = set()

                    # Loop through all functions and instructions in the program
                    for item in funcs_and_instrs:
                        try:
                            if isinstance(item, Function):
                                # Skip if the function has already been processed
                                if item in processed_functions:
                                    continue

                                 # Decompile the function
                                # Decompile the function
                                results = DecompileResults.decompile(currentProgram, item, options, ConsoleTaskMonitor())
                                highFunction = results.getHighFunction()
                                processed_functions.add(item)
                            if highFunction is not None:
               
                                for pcodeOp in highFunction.getPcodeOps():
                                    print(str(pcodeOp) + "\n")
                            else:
                            # Decompile the instruction
                                results = DecompileResults.decompile(program, item.getFunction(), options, ConsoleTaskMonitor())
                                highFunction = results.getHighFunction()
                                if highFunction is not None:
                                    
                                    for pcodeOp in highFunction.getPcodeOps():
                                        print(str(pcodeOp) + "\n")
                        except:
                            continue

                with lock:
                    counter.value += 1
                    print(counter.value)

            except:
                
                return
                # print(multiprocessing.current_process())
                # print(time.time())
                # with lock:
                #     errorCounter.value += 1
                #     errorIDs.append(id)
                #     print(errorCounter.value)
                # if f is not None:
                #     os.remove(f.name)

            decompInterface.dispose()
        
        os.remove(temp.name)

    
#print(outputLines)
# Export the linear view of Binary Ninja in low level intermediate language representation

# Path to the samples
smp_dir = os.getcwd() + "/data/samples"
#smp_dir = '/home/logan/Dev/MicrosoftMalware/train'
#id = '0AnoOZDNbPXIr2MRBSCh'
smp_dir = Path(smp_dir)
counter = Value('i', 0)
errorCounter = Value('i', 0)
lock = Lock()
binLock = Lock()
errorIDs = []
now = time.time()

idList = []

timeList = []
# # Iterate over all files in the samples directory
for file in smp_dir.iterdir():
    # # Get the file name and extension
    name, ext = file.name.split(".")
    # # Skip files that don't have the .bytes extension
    if ext != "bytes":
        continue
    # # Get the file name and extension
    id = name
   
    if smp_dir.joinpath(id + ".pcode").exists() == False:
        idList.append(id)
    elif os.stat(smp_dir.joinpath(id + ".pcode")).st_size == 0:    
        idList.append(id)
    else:
        counter.value += 1
        #print(counter.value)
        continue
        
print(counter.value)
print(len(idList)) 

for each in idList:
    print(each)
    process_file(smp_dir, each)




print(len(idList))
print(errorIDs)


